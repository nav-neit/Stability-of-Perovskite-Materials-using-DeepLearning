{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Autoencoder import Autoencoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler, CSVLogger , ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PSV_data.csv')\n",
    "df_nums = df.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_a</th>\n",
       "      <th>distance_b1</th>\n",
       "      <th>distance_b2</th>\n",
       "      <th>cubic</th>\n",
       "      <th>ortho</th>\n",
       "      <th>eleneg_a</th>\n",
       "      <th>eleneg_b1</th>\n",
       "      <th>eleneg_b2</th>\n",
       "      <th>eleneg_x</th>\n",
       "      <th>hoe_a</th>\n",
       "      <th>...</th>\n",
       "      <th>rp_a</th>\n",
       "      <th>rp_b1</th>\n",
       "      <th>rp_b2</th>\n",
       "      <th>rp_x</th>\n",
       "      <th>rs_a</th>\n",
       "      <th>rs_b1</th>\n",
       "      <th>rs_b2</th>\n",
       "      <th>rs_x</th>\n",
       "      <th>ind_gap</th>\n",
       "      <th>heat_of_formation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.870604</td>\n",
       "      <td>2.912570</td>\n",
       "      <td>2.555464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.0862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.0274</td>\n",
       "      <td>-1.240558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.925597</td>\n",
       "      <td>2.858240</td>\n",
       "      <td>2.692150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.0862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.7810</td>\n",
       "      <td>-1.012833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.059806</td>\n",
       "      <td>2.856817</td>\n",
       "      <td>2.884582</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.0862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.077</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.1399</td>\n",
       "      <td>-1.145090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.887140</td>\n",
       "      <td>2.881822</td>\n",
       "      <td>2.612114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.0862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.112540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.966402</td>\n",
       "      <td>2.870028</td>\n",
       "      <td>2.738541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-2.0862</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.110</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>-1.162859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_a  distance_b1  distance_b2  cubic  ortho  eleneg_a  eleneg_b1  \\\n",
       "0    3.870604     2.912570     2.555464      1      0      0.79       1.93   \n",
       "1    3.925597     2.858240     2.692150      1      0      0.79       1.93   \n",
       "2    4.059806     2.856817     2.884582      1      0      0.79       1.93   \n",
       "3    3.887140     2.881822     2.612114      1      0      0.79       1.93   \n",
       "4    3.966402     2.870028     2.738541      1      0      0.79       1.93   \n",
       "\n",
       "   eleneg_b2  eleneg_x   hoe_a  ...  rp_a  rp_b1  rp_b2  rp_x  rs_a  rs_b1  \\\n",
       "0       1.61      2.96 -2.0862  ...   2.6   1.33  0.905  0.62  1.71  1.045   \n",
       "1       2.18      2.96 -2.0862  ...   2.6   1.33  0.745  0.62  1.71  1.045   \n",
       "2       2.02      2.96 -2.0862  ...   2.6   1.33  1.077  0.62  1.71  1.045   \n",
       "3       1.81      2.96 -2.0862  ...   2.6   1.33  0.935  0.62  1.71  1.045   \n",
       "4       1.78      2.96 -2.0862  ...   2.6   1.33  1.110  0.62  1.71  1.045   \n",
       "\n",
       "   rs_b2  rs_x  ind_gap  heat_of_formation  \n",
       "0   0.77  0.58   1.0274          -1.240558  \n",
       "1   0.67  0.58   0.7810          -1.012833  \n",
       "2   0.92  0.58   1.1399          -1.145090  \n",
       "3   0.76  0.58   0.0000          -1.112540  \n",
       "4   0.94  0.58   0.1818          -1.162859  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the redundant columns and dependent variables\n",
    "df_nums = df_nums.drop(['ortho','ind_gap','heat_of_formation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_nums.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch<25:\n",
    "        return lr\n",
    "    elif epoch >=25 and epoch < 50:\n",
    "        return lr*0.99\n",
    "    elif epoch >=50 and epoch <75:\n",
    "        return lr*0.98\n",
    "    else:\n",
    "        return lr*0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = LearningRateScheduler(\n",
    "    scheduler,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    patience=3,\n",
    "    factor=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv = CSVLogger(\n",
    "    'autoencoder_logs.csv',\n",
    "    separator = ',',\n",
    "    append=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(latent_dim = 10, out_dims=32)\n",
    "autoencoder.compile(optimizer=tf.optimizers.Adam(learning_rate=0.02), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "108/108 [==============================] - 1s 2ms/step - loss: 0.1242 - lr: 0.0200\n",
      "Epoch 2/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0901 - lr: 0.0200\n",
      "Epoch 3/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0782 - lr: 0.0200\n",
      "Epoch 4/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0610 - lr: 0.0200\n",
      "Epoch 5/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0567 - lr: 0.0200\n",
      "Epoch 6/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0512 - lr: 0.0200\n",
      "Epoch 7/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0468 - lr: 0.0200\n",
      "Epoch 8/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0484 - lr: 0.0200\n",
      "Epoch 9/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0513 - lr: 0.0200\n",
      "Epoch 10/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0566 - lr: 0.0200\n",
      "Epoch 11/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0530 - lr: 0.0180\n",
      "Epoch 12/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0403 - lr: 0.0180\n",
      "Epoch 13/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0370 - lr: 0.0180\n",
      "Epoch 14/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0348 - lr: 0.0180\n",
      "Epoch 15/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0387 - lr: 0.0180\n",
      "Epoch 16/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0391 - lr: 0.0180\n",
      "Epoch 17/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0525 - lr: 0.0180\n",
      "Epoch 18/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0452 - lr: 0.0162\n",
      "Epoch 19/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0352 - lr: 0.0162\n",
      "Epoch 20/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0299 - lr: 0.0162\n",
      "Epoch 21/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0328 - lr: 0.0162\n",
      "Epoch 22/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0328 - lr: 0.0162\n",
      "Epoch 23/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0302 - lr: 0.0162\n",
      "Epoch 24/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0354 - lr: 0.0146\n",
      "Epoch 25/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0300 - lr: 0.0146\n",
      "Epoch 26/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0267 - lr: 0.0146\n",
      "Epoch 27/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0259 - lr: 0.0146\n",
      "Epoch 28/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0257 - lr: 0.0146\n",
      "Epoch 29/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0270 - lr: 0.0146\n",
      "Epoch 30/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0306 - lr: 0.0146\n",
      "Epoch 31/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0276 - lr: 0.0146\n",
      "Epoch 32/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0276 - lr: 0.0131\n",
      "Epoch 33/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0216 - lr: 0.0131\n",
      "Epoch 34/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0207 - lr: 0.0131\n",
      "Epoch 35/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0227 - lr: 0.0131\n",
      "Epoch 36/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0218 - lr: 0.0131\n",
      "Epoch 37/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0317 - lr: 0.0131\n",
      "Epoch 38/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0267 - lr: 0.0118\n",
      "Epoch 39/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0185 - lr: 0.0118\n",
      "Epoch 40/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0188 - lr: 0.0118\n",
      "Epoch 41/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0196 - lr: 0.0118\n",
      "Epoch 42/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0184 - lr: 0.0118\n",
      "Epoch 43/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0172 - lr: 0.0106\n",
      "Epoch 44/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0209 - lr: 0.0106\n",
      "Epoch 45/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0199 - lr: 0.0106\n",
      "Epoch 46/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0171 - lr: 0.0106\n",
      "Epoch 47/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0161 - lr: 0.0096\n",
      "Epoch 48/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0158 - lr: 0.0096\n",
      "Epoch 49/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0165 - lr: 0.0096\n",
      "Epoch 50/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0164 - lr: 0.0096\n",
      "Epoch 51/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0157 - lr: 0.0096\n",
      "Epoch 52/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0156 - lr: 0.0086\n",
      "Epoch 53/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0161 - lr: 0.0086\n",
      "Epoch 54/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0162 - lr: 0.0086\n",
      "Epoch 55/100\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0184 - lr: 0.0086\n",
      "Epoch 56/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0151 - lr: 0.0077\n",
      "Epoch 57/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0148 - lr: 0.0077\n",
      "Epoch 58/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0152 - lr: 0.0077\n",
      "Epoch 59/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0151 - lr: 0.0077\n",
      "Epoch 60/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0159 - lr: 0.0077\n",
      "Epoch 61/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0141 - lr: 0.0070\n",
      "Epoch 62/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0140 - lr: 0.0070\n",
      "Epoch 63/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0132 - lr: 0.0070\n",
      "Epoch 64/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0136 - lr: 0.0070\n",
      "Epoch 65/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0133 - lr: 0.0070\n",
      "Epoch 66/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0126 - lr: 0.0070\n",
      "Epoch 67/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0127 - lr: 0.0070\n",
      "Epoch 68/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0125 - lr: 0.0070\n",
      "Epoch 69/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0128 - lr: 0.0070\n",
      "Epoch 70/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0125 - lr: 0.0063\n",
      "Epoch 71/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0123 - lr: 0.0063\n",
      "Epoch 72/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0124 - lr: 0.0063\n",
      "Epoch 73/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0136 - lr: 0.0063\n",
      "Epoch 74/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0118 - lr: 0.0063\n",
      "Epoch 75/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0122 - lr: 0.0063\n",
      "Epoch 76/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0122 - lr: 0.0063\n",
      "Epoch 77/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0118 - lr: 0.0063\n",
      "Epoch 78/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0121 - lr: 0.0056\n",
      "Epoch 79/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0114 - lr: 0.0056\n",
      "Epoch 80/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0116 - lr: 0.0056\n",
      "Epoch 81/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0114 - lr: 0.0056\n",
      "Epoch 82/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0111 - lr: 0.0056\n",
      "Epoch 83/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0115 - lr: 0.0056\n",
      "Epoch 84/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0114 - lr: 0.0056\n",
      "Epoch 85/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0113 - lr: 0.0056\n",
      "Epoch 86/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0115 - lr: 0.0051\n",
      "Epoch 87/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0130 - lr: 0.0051\n",
      "Epoch 88/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0120 - lr: 0.0051\n",
      "Epoch 89/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0109 - lr: 0.0046\n",
      "Epoch 90/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0109 - lr: 0.0046\n",
      "Epoch 91/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0113 - lr: 0.0046\n",
      "Epoch 92/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0109 - lr: 0.0046\n",
      "Epoch 93/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0107 - lr: 0.0041\n",
      "Epoch 94/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0107 - lr: 0.0041\n",
      "Epoch 95/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0107 - lr: 0.0041 0.0\n",
      "Epoch 96/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0107 - lr: 0.0041\n",
      "Epoch 97/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0105 - lr: 0.0037\n",
      "Epoch 98/100\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.0107 - lr: 0.0037\n",
      "Epoch 99/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0106 - lr: 0.0037 0.\n",
      "Epoch 100/100\n",
      "108/108 [==============================] - 0s 2ms/step - loss: 0.0112 - lr: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b22cf4df0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_scaled, X_scaled, epochs=100,batch_size=5,shuffle=True,callbacks=[rlr,log_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of the model: 1.03 %\n"
     ]
    }
   ],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "X_pred = autoencoder.call(X_scaled)\n",
    "error = mse(X_pred,X_scaled).numpy()\n",
    "print(f'Error of the model: {error*100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.read_csv('autoencoder_logs.csv')\n",
    "loss = logs['loss'].values\n",
    "epochs = range(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(epochs,loss,color='red')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss vs Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = np.array(autoencoder.encoder(X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(encoded_features, columns = ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.944244</td>\n",
       "      <td>-0.467843</td>\n",
       "      <td>-0.250634</td>\n",
       "      <td>-0.607917</td>\n",
       "      <td>0.722437</td>\n",
       "      <td>2.718357</td>\n",
       "      <td>1.390860</td>\n",
       "      <td>0.095709</td>\n",
       "      <td>-0.376503</td>\n",
       "      <td>-0.381374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.184422</td>\n",
       "      <td>-0.263323</td>\n",
       "      <td>-0.406619</td>\n",
       "      <td>1.421094</td>\n",
       "      <td>1.284893</td>\n",
       "      <td>3.853995</td>\n",
       "      <td>1.308007</td>\n",
       "      <td>-0.123640</td>\n",
       "      <td>1.368393</td>\n",
       "      <td>0.935994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.381459</td>\n",
       "      <td>-0.321316</td>\n",
       "      <td>-0.360481</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>1.159082</td>\n",
       "      <td>3.447642</td>\n",
       "      <td>1.226776</td>\n",
       "      <td>-0.085541</td>\n",
       "      <td>0.499673</td>\n",
       "      <td>0.133785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.791677</td>\n",
       "      <td>-0.419213</td>\n",
       "      <td>-0.270855</td>\n",
       "      <td>-0.446005</td>\n",
       "      <td>0.817097</td>\n",
       "      <td>2.801008</td>\n",
       "      <td>1.504990</td>\n",
       "      <td>-0.020920</td>\n",
       "      <td>-0.254898</td>\n",
       "      <td>-0.273302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.785569</td>\n",
       "      <td>-0.452266</td>\n",
       "      <td>-0.316529</td>\n",
       "      <td>-0.389248</td>\n",
       "      <td>0.983658</td>\n",
       "      <td>3.238737</td>\n",
       "      <td>0.938708</td>\n",
       "      <td>0.085265</td>\n",
       "      <td>-0.219014</td>\n",
       "      <td>-0.267498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.298216</td>\n",
       "      <td>-0.293468</td>\n",
       "      <td>-0.372609</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>1.181730</td>\n",
       "      <td>3.559220</td>\n",
       "      <td>1.301948</td>\n",
       "      <td>-0.104680</td>\n",
       "      <td>0.844347</td>\n",
       "      <td>0.472531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.090993</td>\n",
       "      <td>-0.436903</td>\n",
       "      <td>-0.027316</td>\n",
       "      <td>-0.730014</td>\n",
       "      <td>-0.254356</td>\n",
       "      <td>2.922050</td>\n",
       "      <td>1.484697</td>\n",
       "      <td>0.668205</td>\n",
       "      <td>-0.545271</td>\n",
       "      <td>-0.230886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.201218</td>\n",
       "      <td>-0.236212</td>\n",
       "      <td>-0.325626</td>\n",
       "      <td>1.477631</td>\n",
       "      <td>0.465371</td>\n",
       "      <td>4.083724</td>\n",
       "      <td>1.383063</td>\n",
       "      <td>-0.082988</td>\n",
       "      <td>1.223730</td>\n",
       "      <td>1.462274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.398914</td>\n",
       "      <td>-0.304898</td>\n",
       "      <td>-0.297773</td>\n",
       "      <td>0.251982</td>\n",
       "      <td>0.490377</td>\n",
       "      <td>3.694568</td>\n",
       "      <td>1.197765</td>\n",
       "      <td>-0.044571</td>\n",
       "      <td>0.385097</td>\n",
       "      <td>0.562741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.877619</td>\n",
       "      <td>-0.400119</td>\n",
       "      <td>-0.124019</td>\n",
       "      <td>-0.506610</td>\n",
       "      <td>-0.107306</td>\n",
       "      <td>3.016967</td>\n",
       "      <td>1.446535</td>\n",
       "      <td>0.316221</td>\n",
       "      <td>-0.354654</td>\n",
       "      <td>-0.157876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0 -0.944244 -0.467843 -0.250634 -0.607917  0.722437  2.718357  1.390860   \n",
       "1 -0.184422 -0.263323 -0.406619  1.421094  1.284893  3.853995  1.308007   \n",
       "2 -0.381459 -0.321316 -0.360481  0.190600  1.159082  3.447642  1.226776   \n",
       "3 -0.791677 -0.419213 -0.270855 -0.446005  0.817097  2.801008  1.504990   \n",
       "4 -0.785569 -0.452266 -0.316529 -0.389248  0.983658  3.238737  0.938708   \n",
       "5 -0.298216 -0.293468 -0.372609  0.674147  1.181730  3.559220  1.301948   \n",
       "6 -1.090993 -0.436903 -0.027316 -0.730014 -0.254356  2.922050  1.484697   \n",
       "7 -0.201218 -0.236212 -0.325626  1.477631  0.465371  4.083724  1.383063   \n",
       "8 -0.398914 -0.304898 -0.297773  0.251982  0.490377  3.694568  1.197765   \n",
       "9 -0.877619 -0.400119 -0.124019 -0.506610 -0.107306  3.016967  1.446535   \n",
       "\n",
       "         x8        x9       x10  \n",
       "0  0.095709 -0.376503 -0.381374  \n",
       "1 -0.123640  1.368393  0.935994  \n",
       "2 -0.085541  0.499673  0.133785  \n",
       "3 -0.020920 -0.254898 -0.273302  \n",
       "4  0.085265 -0.219014 -0.267498  \n",
       "5 -0.104680  0.844347  0.472531  \n",
       "6  0.668205 -0.545271 -0.230886  \n",
       "7 -0.082988  1.223730  1.462274  \n",
       "8 -0.044571  0.385097  0.562741  \n",
       "9  0.316221 -0.354654 -0.157876  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df[['ind_gap','heat_of_formation']]\n",
    "data_final = pd.concat([df_new,y_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('../deeplearningModel/encoded_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acd80a346a21103701aea104b3122a4c1b4265913b6808a7645293b85518db46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
